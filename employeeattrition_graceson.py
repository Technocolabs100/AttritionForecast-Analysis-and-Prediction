# -*- coding: utf-8 -*-
"""EmployeeAttrition_Graceson.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/190f8Z_SMTbsFAT9P7BChrpP7tPZUf2z-
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, mean_squared_error, r2_score

df = pd.read_csv("/content/WA_Fn-UseC_-HR-Employee-Attrition.csv")

"""checking for missing values"""

df.isna().sum()

"""Data Exploration"""

df.info()

df.describe()

"""Checking for outlayers"""

sns.boxplot(data=df)

numeric_cols = df.select_dtypes(include=[np.number]).columns

for column in numeric_cols:
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    df = df[~((df[column] < (Q1 - 1.5 * IQR)) | (df[column] > (Q3 + 1.5 * IQR)))]

"""Ensure consistency in categorical data"""

categorical_cols = df.select_dtypes(include=['object']).columns
for column in categorical_cols:
    df[column] = df[column].astype(str).str.strip().str.lower()

"""Data Encoding"""

binary_columns = [col for col in df.columns if df[col].nunique() == 2]
print("Binary columns:", binary_columns)

if 'Attrition' not in binary_columns:
    df['Attrition'] = le.fit_transform(df['Attrition'])

la = LabelEncoder()
for column in binary_columns:
    df[column] = la.fit_transform(df[column])

"""one-hot encoding"""

multi_class_columns = ['BusinessTravel', 'Department', 'EducationField', 'JobRole', 'MaritalStatus']
df = pd.get_dummies(df, columns=multi_class_columns, drop_first=True)

df.info()

"""Splitting the data into features and target"""

X = df.drop(columns=['Attrition', 'MonthlyIncome','Over18'])
y_classification = df['Attrition']
y_regression = df['MonthlyIncome']

""" Splitting the data into training and testing sets"""

X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X, y_classification, test_size=0.2, random_state=42)
X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_regression, test_size=0.2, random_state=42)

"""Regression Model"""

reg_model = LinearRegression()
reg_model.fit(X_train_reg, y_train_reg)
y_pred_reg = reg_model.predict(X_test_reg)

mse = mean_squared_error(y_test_reg, y_pred_reg)
r2 = r2_score(y_test_reg, y_pred_reg)

print("Regression Report")
print(f"Mean Squared Error: {mse}")
print(f"R^2 Score: {r2}")

"""Classification Model

"""

clf_model = LogisticRegression(max_iter=1000)
clf_model.fit(X_train_clf, y_train_clf)
y_pred_clf = clf_model.predict(X_test_clf)

"""Classification Report

"""

conf_matrix = confusion_matrix(y_test_clf, y_pred_clf)
acc_score = accuracy_score(y_test_clf, y_pred_clf)
class_report = classification_report(y_test_clf, y_pred_clf)

print("\nClassification Report")
print(f"Accuracy Score: {acc_score}")
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(class_report)

"""Plotting the confusion matrix

"""

sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""Save the cleaned and encoded dataset"""

df.to_csv('cleanedemployee_data.csv', index=False)

"""## Our regression model aimed to predict employees' monthly income based on various factors. The model is quite effective, explaining about 80% of the variations in income among employees. This indicates that our model captures most of the factors influencing monthly income. However, there's still some room for improvement, as the difference between predicted and actual incomes is relatively high.

## We also built a model to predict whether an employee is likely to leave the company (attrition). The model correctly identifies employees who stay with the company 96% of the time and those who leave 22% of the time. Overall, the model accurately predicts employee status 83.6% of the time.

## However, the model struggles with predicting attrition accurately. It misses a significant number of actual attrition cases and also incorrectly predicts some employees as likely to leave when they are not. Specifically:

## It correctly identified 112 employees who stayed and 5 who left.
## It incorrectly identified 18 employees who left as staying and 5 who stayed as leaving.

###  Income Prediction: Our model is quite good at predicting monthly income but could be refined further to reduce prediction errors.
### Attrition Prediction: While the model is generally good at identifying employees who stay, it needs improvement in predicting those who are likely to leave. This is crucial for proactive retention strategies.
"""

pip install tabpy

